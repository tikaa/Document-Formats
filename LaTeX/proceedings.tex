\documentclass{sigchi}

% Use this section to set the ACM copyright statement (e.g. for
% preprints).  Consult the conference website for the camera-ready
% copyright statement.

% Copyright
\CopyrightYear{2016}
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
% DOI
\doi{http://dx.doi.org/10.475/123_4}
% ISBN
\isbn{123-4567-24-567/08/06}
%Conference
\conferenceinfo{CHI'16,}{May 07--12, 2016, San Jose, CA, USA}
%Price
\acmPrice{\$15.00}

% Use this command to override the default ACM copyright statement
% (e.g. for preprints).  Consult the conference website for the
% camera-ready copyright statement.

%% HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP --
%% Please note you need to make sure the copy for your specific
%% license is used here!
% \toappear{
% Permission to make digital or hard copies of all or part of this work
% for personal or classroom use is granted without fee provided that
% copies are not made or distributed for profit or commercial advantage
% and that copies bear this notice and the full citation on the first
% page. Copyrights for components of this work owned by others than ACM
% must be honored. Abstracting with credit is permitted. To copy
% otherwise, or republish, to post on servers or to redistribute to
% lists, requires prior specific permission and/or a fee. Request
% permissions from \href{mailto:Permissions@acm.org}{Permissions@acm.org}. \\
% \emph{CHI '16},  May 07--12, 2016, San Jose, CA, USA \\
% ACM xxx-x-xxxx-xxxx-x/xx/xx\ldots \$15.00 \\
% DOI: \url{http://dx.doi.org/xx.xxxx/xxxxxxx.xxxxxxx}
% }

% Arabic page numbers for submission.  Remove this line to eliminate
% page numbers for the camera ready copy
% \pagenumbering{arabic}

% Load basic packages
\usepackage{balance}       % to better equalize the last page
\usepackage{graphics}      % for EPS, load graphicx instead 
\usepackage[T1]{fontenc}   % for umlauts and other diaeresis
\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage[pdflang={en-US},pdftex]{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{textcomp}

%my packages
\usepackage{pdflscape}
\usepackage{csquotes}
\usepackage{array}
\usepackage{tcolorbox}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{datetime}
\usepackage{cite}

% Some optional stuff you might like/need.
\usepackage{microtype}        % Improved Tracking and Kerning
% \usepackage[all]{hypcap}    % Fixes bug in hyperref caption linking
\usepackage{ccicons}          % Cite your images correctly!
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% If you want to use todo notes, marginpars etc. during creation of
% your draft document, you have to enable the "chi_draft" option for
% the document class. To do this, change the very first line to:
% "\documentclass[chi_draft]{sigchi}". You can then place todo notes
% by using the "\todo{...}"  command. Make sure to disable the draft
% option again before submitting your final document.
\usepackage{todonotes}

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.
\def\plaintitle{Understanding Data for Implementing Privacy in Software Systems}
\def\plainauthor{First Author, Second Author, Third Author,
  Fourth Author, Fifth Author, Sixth Author}
\def\emptyauthor{}
\def\plainkeywords{Authors' choice; of terms; separated; by
  semicolons; include commas, within terms only; required.}
\def\plaingeneralterms{Documentation, Standardization}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{
    \def\UrlFont{\sf}
  }{
    \def\UrlFont{\small\bf\ttfamily}
  }}
\makeatother
\urlstyle{leo}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
% Use \plainauthor for final version.
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  pdfdisplaydoctitle=true, % For Accessibility
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
  hypertexnames=false
}

% create a shortcut to typeset table headings
% \newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{\plaintitle}

\numberofauthors{3}
\author{%
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
}

\maketitle

\begin{abstract}
Modern software systems continue to collect personal data in large scale for various economic and social benefits. These personal data carries information about users. If systems collect personal data that is too sensitive to users without necessary measures to protect these data, this could lead to privacy vulnerabilities. Therefore, developers are required to implement privacy to protect data in systems. Understanding the personal data collected and stored in systems could help developers to implement privacy when they design systems. However, currently, there is no method that guide developers to understand data. In this research we investigate how understanding data could help developers to implement privacy in software systems. Our findings in this research indicate that developers find it easy to implement privacy when collecting, storing and sharing data in software system designs when they understand the personal data they use in systems.
\end{abstract}

\category{H.5.m.}{Information Interfaces and Presentation
  (e.g. HCI)}{Miscellaneous} \category{See
  \url{http://acm.org/about/class/1998/} for the full list of ACM
  classifiers. This section is required.}{}{}

\keywords{Privacy Engineering, Software Development, Software Engineering, Data Minimization}

\section{Introduction} 

Modern software systems such as Internet of Things, Social Networking Systems and smart home systems are extremely dependent on our data. These systems collect large amounts of our personal data such as our birthday, identification numbers, phone numbers and even the medicine we take, and our daily schedules \cite {new2013google, the2017the}. Collection and use of personal data in software systems have become a necessity than a choice due to the various social and economic benefits data could bring into systems  \cite {marr2015big, tene2012big}. For example, collecting data from users' medical profiles could predict a patient's chances of being diagnosed with cancer based on his/her symptoms. Connecting this data against users' financial records one could predict the chances of a user opting for a health insurance. However, collection and use of personal data also imposes a risk of losing one's private information \cite {european2016data}. This may lead to identity hack in the internet (posing as someone else to get access to a bank account or interact with others) and cause financial and reputation loss to users. Therefore, users are concerned about how systems collect, store and share their data. For example, connecting data from different user profiles across platforms such as Facebook and WhatsApp raised concerns among users on the possibility of revealing information about them (such as their friend networks and messaging history) to outsiders which may not be observable if the data remained isolated in either platform \cite {zingales2017between}. Therefore, it is important for developers to understand and acknowledge these user concerns when they design software systems.

Users' privacy concerns when interacting with software systems are associated with the data they disclose to the systems. It is said that users are more concerned about disclosing data into software systems if the data requested is sensitive (such as their health data), or/and irrelevant for the system that requests data \cite {malheiros2013fairly, malhotra2004internet}. For example, if a social networking application request their banking details users are most likely to decline compared to disclosing their banking details to make an online payment due to privacy concerns. Therefore, in order to understand user privacy concerns, developers should understand the data they use in system designs from a user perspective \cite {marr2015big, tene2012big}. If developers could see and understand these differences, and understand data from a user perspective, they could significantly lower the costs and risks involved in storing and securing large amounts of data in software systems \cite {marr2015big, tene2012big, rubinstein2012big}. However, current privacy guidelines such as Privacy by Design (PbD) and Data Minimization are criticized for not accounting for these user concerns when embedding privacy into system designs \cite {spiekermann2012challenges}. Heretofore, to our cost, there is no method that guide developers to understand and incorporate user privacy concerns associated with their data when designing software systems \cite {omoronyia2013engineering, thomas2014distilling, senarath2018understanding}.

Previous research have identified sensitivity of data, visibilty data gets in a system and relevance of data to the system that request data as attributes that contribute to the concerns users have towards their data when users interact with software systems \cite {malheiros2013fairly, malhotra2004internet}. These attributes define the privacy risk associated with data when users interact with software systems \cite {bansal2010impact, minkus2014scale, maximilien2009privacy}. Therefore, when we say understanding data from a user perspective, we focus on how understanding these attributes of data could help developers to focus on privacy in data collection, storage and sharing when they design systems. We conduct two studies in this paper. First, through a survey we observe how understanding the above attributes of data could help developers to embed privacy into software systems. Then, building on previous work [HICSS paper], we develop a work-flow that guide developers to implement privacy in a system design through understanding data and conduct 3 workshops to observe how this work-flow could help developers to implement privacy when they design software systems.

Our main findings in this work are as follows :

\begin{itemize}
\item We show that 91\% developers in our studies believed understanding data would help them to implement better privacy when they design systems. Developers show that when they understood the data they use they could understand why and how to protect data.
\item We show that 85\% developers in our studies believed understanding data would help them to better decide on collecting, storing and sharing data in their systems. It was easy for developers to decide on sharing and storing data securely when they understood the data from a user perspective.
\end {itemize}

This paper is structured as follows. We first discuss previous work on privacy to show why understanding data is important for implementing privacy in system designs. Then we discuss the background for understanding data which lead to selecting data sensitivity, relevance and visibility as the attributes of focus for understanding data. Next, we discuss the methodology followed by the two user studies we conducted and the results to show how understanding data helps developers to implement privacy. In the discussion section we discuss the implications of our results and how our results could help the current approach towards implementing privacy in software systems. Finally, we present our conclusions and future directions to continue this research.

\section {Related work}

Previous research suggests that developers are required to understand user privacy concerns and data when they design systems  \cite{ramokapane2017feel, rao2016expecting, lin2012expectation, kalloniatis2008addressing, senarath2018understanding}. A recent study on developers capability of understanding user privacy needs has shown that the privacy perceived by developers when they interact with software systems is significantly different to that of users \cite {senarath2018understanding}. This suggests that developers are not capable of seeing users' privacy concerns when they disclose their data into systems. Developers rather design the application to collect, store and share data based on the application's business requirements \cite {senarath2018under, senarath2018understanding}. This leads to systems not catering for user privacy needs and data protection, which could result in privacy vulnerabilities in software systems. Therefore, developers require guidance to help them to understand privacy from a user perspective when they embed privacy into software systems \cite {senarath2018under}. 

Previous research has defined that disclosure of a data item leads to loss of privacy, and confidentiality leads to privacy \cite {gurses2014can}. However, this may not be realistic in the context of modern software systems. Simply disclosing a data item in a system may not have an impact on user's privacy if the system has appropriate privacy techniques (such as anonymization, aggregation and encryption) implemented in the system to protect data. When users interact with systems that collect their data, they perceive a privacy risk \cite {malheiros2013fairly}. For example, when installing a mobile app in his/her device the user is prompted to give permission to the app to access data from the device. Users' decisions to deny or allow these access notifications are based on the risk the they perceive in disclosing data to the app \cite {kobsa2007privacy, li2010understanding, malhotra2004internet}, and this risk is directly associated with the data being disclosed. However, this risk associated with the data is unknown to the developer. In order to implement \enquote{appropriate privacy techniques} for data in a system design, developers need to understand these user privacy concerns associated with the data they use in the system.  

Knowing the privacy concerns/risks users have associated with the data used in software systems could help developers to embed privacy into software systems \cite {senarath2018under, marr2015big, tene2012big, rubinstein2012big}. Developers could implement measures to protect data that users consider to have a higher privacy risk so that systems address user privacy concerns. However, for this first developers need to identify the attributes of data that contributes to the privacy concerns users have when they disclose data into software systems. 

Bansal et al. \cite {bansal2010impact} have shown that users' intention to disclose health information is affected by the sensitivity of the data. Similarly, Malhotra et al. \cite {malhotra2004internet} have shown that consumers' willingness to share personal data in commercial platforms is affected by the sensitivity of the data. Similarly, Malheiros et al. \cite {malheiros2013fairly} have shown that sensitivity of data items such as date of birth and occupation had a significant affect on the decisions of the users to disclose that data into software systems. These findings suggest that data sensitivity has an impact on the privacy concerns users have towards their data.

Consequently, Maximilien et al. \cite {maximilien2009privacy} have shown that the the privacy risk of data increases monotonically with the sensitivity of data and visibility of data in a system. Using this relationship, Minkus and Memon \cite {minkus2014scale} have measured the privacy of users in Facebook by multiplying the sensitivity of their content with the visibility based on the user's privacy settings. Both these approaches measure the privacy risk of users when they interact with systems that are developed and functioning. Making use of this work Senarath and Arachchilage [HICSS paper] have introduced a model that help developers to measure user privacy risk of data. They have shown that if developers could rank and categorize data on data sensitivity, data visibility and relevance developers can measure the perceived privacy risk by a users when they disclose the particular data item into the system. They argue that this model would be useful for developers.

We believe that the initiative by Senarath and Arachchilage [HICSS paper] is a good entry point for integrating user aspects of privacy into the software development process. At the same time it is imperative to investigate if understanding data could help developers to implement privacy in software systems if they understand data following this model. In this research we focus on enabling developers to understand user data and understand this privacy risk associated with the data they use in systems. Our goal is to observe if understanding data would help developers to implement better privacy when they design software systems. 


\section{Methodology}

 The following digram shows how we propose the understanding data to fit in the existing system design process.

%\begin{figure}[h]
%\begin{center}
%\includegraphics[width=0.5\textwidth]{figures/understandingData.JPG}
%\caption{How the concept of understanding data would fit in the system design process, when deciding on data usage in a software system. Once the initial decision to collect data is made, before designing the system, developers should understand data. They can refine the data collection decisions and design the system to protect data and user privacy based on the understanding gained. }
%\end{center}
%\end{figure}

As discussed, in terms of understanding data we focus on understanding the privacy risk associated with data from a user perspective. The model  proposed by Senarath and Arachchilage [HICSS paper to appear] defines data sensitivity, data visibility, data relevance and the as the parameters that affects the privacy risk of data. In order to use this model developers are required to determine 
\begin{itemize}
\item How sensitive data would be for a user (highly sensitive, moderately sensitive, low sensitive) ?
\item How visible the data would be in the system (highly visible, moderately visible, low visible) ? and
\item How relevant the data is to the system (highly relevant, moderately relevant, low relevant) ?
\end{itemize}

Therefore, the first experiment in this research was conducted to observe how developer perceive this ranking and scaling process, and if this helps them to understand data and implement privacy in a system design. 

\section {Study I }

We conducted this as a remote study because of the practical difficulties in recruiting developers with diverse backgrounds for a in lab experiment. Furthermore, we wanted the participants to participate at home or at work, which would make them behave closer to how they naturally work \cite {wermke2017security, acar2017comparing}. We recruited participants through personal connections and crowd-sourcing, by inviting Github users who are actively contributing to end user applications (Java and PHP) \cite {wermke2017security}. We first sent 6000 invitation email explaining the study and asked for expression of interest for participation, filtering Github users who had the highest number of commits in most popular Java and PhP repositories in October to December in 2016. The invitation requested voluntary participation. Once the participant expressed interest for participation, we emailed the study guide and the consent form via email. Participants were asked to sign and complete the consent form prior to participation. We received 118 expressions of interest within three weeks, out of which 25 agreed to participate in the study after receiving the study guide (~0.0042\% participant rate). After checking answer quality, we removed one participant's submission because the participant had contrasting answers. We thanked the expressions of interests we received after the three weeks period and kept their contact details for future studies.

The experiment was designed based on an application scenario. We defined a health-care application which would allow users to get medical advice through a software application (complete application scenario available in appendix). The experiment involved several steps as below. Participants were first asked to read and understand the application scenario used for the experiment. Then the participants were guided to follow the steps below.

\begin{itemize}
\item Developers were asked to decide the data they wanted to collect for the system:  This step made developers to decide on the data items they want to use in the system. This is the baseline data set with which developers worked in the next steps in the remainder of the experiment.
\item Developers were asked to decide how they wanted to store and share data (draw the information flow diagram for the system on paper). Developers were asked to explicitly consider data privacy when they designed the system : This step allowed us to see how developers would approach data privacy when they were asked to.
\item Developers were asked to scale and rank data according to data sensitivity, visibility and relevance for the system being designed : This step guided the developers through the model we are proposing. Similar to the work done by Senarath and Arachchilage, here we asked the developers to rank and scale data they decided to collect according to the the categorization in table 01. 

\begin{center}
\begin{table*}[htbp]
\caption{Data Categorization}
\begin{center}
 \begin{tabular}{|m{2em}|m{14em}|m{14em}|m{14em}|} 
 \hline
\textbf{Scale} & \textbf{ Sensitivity} & \textbf{ Visibility} & \textbf{ Relatedness}\\
\hline
1 & Category S1 : Highly sensitive data elements, loss of data would impose serious damage to the privacy of the data owner &  Category V1 : Highly visible, similar to publicly posted content in Facebook, anyone can access without the knowledge of the data owner & Category R1 : Extremely related data the application cannot do without. For example, the location information for a tracking application\\
\hline
2 & Category S2 : Sensitive elements, loss would impose considerable damage to the privacy of the data owner & Category V2 : Relatively visible, similar to \textit{friends only} content in Faceboook, a limited set of users access the content without the knowledge of the data owner & Category R2 : Related data that provide features that add significant value to the application. For example, the location information for a restaurant finder\\
\hline
3 & Category S3 : Low sensitive elements, loss would impose limited, calculable and bearable damage to the privacy of the data owner & Category V3 : Not visible, similar to the \textit {only me} content in Facebook, no one can access the data without the knowledge of the data owner & Category R3 : Remotely related to the purpose and provide optional features in the application. For example, location information for a trip planner\\
\hline
\end{tabular}
\end{center}
\end{table*}
\end{center}


\item Exit questionnaire to give feedback on the scaling and ranking process and answer questions (questionnaire available in the appendix) :  This step involved questions on how developers perceived the steps they followed, and how they think the scaling and ranking data would help them to understand data. The questions focused on how the understanding gained through the ranking and scaling process would help developers to implement data minimization in the system design. This was investigated through  Pfitzmann et al. \cite {pfitzmann2010terminology} and Gurses's \cite {gurses2015engineering} proposed methods to implement data minimization in systems. We asked developers if they would change their initial design and if they had a better idea to implement data minimization in the system design based on the understanding. The questions for the exit survey were hosted as a Google form. 
\end{itemize}


\subsection {Results}

Table 02 below shows how developers believed the ranking and scaling process they followed. 


\begin{center}
\begin{table*}[htbp]
\caption{Study I - results}
\begin{center}

\begin{tabular}{|p{0.7\linewidth}|p{0.06\linewidth}|p{0.06\linewidth}|p{0.06\linewidth}|} 
\hline
\multirow{2}{*}{Question}& \multicolumn{3}{|c|}{Percentage Response}\\   \cline{2-4}
&Yes&No&Maybe\\
\hline
Do you think that the categorization task gave you more understanding of the data you collected? & 91 & 9 & 0\\
\hline
After this categorization, do you think you could have further refined your data collection decisions? & 74 & 26 & 0 \\
\hline
After this categorization, do you think you have a better understanding on how you should access, save, change and share different data in your application? & 87 & 13 & 0 \\
\hline
After this categorization, do you get an understanding on how to perform privacy notifications and policies? & 83 & 17 & 0\\
\hline
After this categorization, do you get an understanding on testing the privacy aspects of this application? & 74 & 26 & 0\\
\hline
After this categorization, do you get an understanding on how to perform pseudonimization in this application? & 30 & 48 & 22\\
\hline
After this categorization, do you get an understanding on how to perform anonymization in this application? & 70 & 26 & 4\\
\hline
After this categorization, do you get an understanding on how to perform data aggregation and  separation in the database design in this application? & 65 & 26 & 9 \\
\hline
After this categorization, do you get an understanding on how to perform data encryption in this application? & 74 & 26 & 0 \\
\hline
After this categorization, do you get an understanding on how to implement unobservability and undetectability of data in this application? & 65 & 32 & 3 \\
\hline
\end{tabular}

\end{center}
\end{table*}
\end{center}

The main findings of this study are,

\begin{itemize}
\item 91\% of the developers in the study said that the data categorization they did have them more understanding of the data they used in the system. 
\item 87\% of the developers in the study said that the data categorization helped them to decide how to access, save, change and share different data in the system design.
\item 74\% of the developers in the study said that they could further refine their data collection decisions based on understanding they gained through the exercise.
\end {itemize}

Since developers had actually done a design for the system prior to answering these questions, the answers are contextualized. They had an understanding of the way they already designed the system. Following the exercise they were reflecting on the decisions they made rather than hypothesizing on a system design they never designed. These results gave us an idea about the way developers perceived the concept of understanding data we proposed. The results showed that developers were positive about the approach and they believed it could help them protect data in their system designs. However, the results did not show how the approach would perform when developers actually design systems. Therefore, in order to interpret the quantitative results we obtained in this study and to observe how developers would actually engage with the approach we propose.

\section{study II}

This experiment was designed as a qualitative experiment. In this experiment we needed to observe participants' engagement with the model, how they interact and react to the model in order to interpret the quantitative results we obtained through the survey. Therefore, we decided to conduct a participant observation workshop \cite {venable2016feds, gregor2013positioning}. 

However, in order to conduct a workshop we needed to have a complete work-flow for the participants to follow. Therefore, based on the model proposed by Senarath and Arachchilage, we first defined a simple privacy engineering flow for understanding data. We call this work-flow as a \textit{Model for Understanding Data}.

\section {Experiment Design : Model for Understanding Data}

This model has the concept of understanding data and the perceived privacy risk associated with data in its core. The model defines steps for developers to follow.

%\begin{figure*}[h]
%\begin{center}
%\includegraphics[width=0.8\textwidth]{figures/dataItem_NEW}
%\caption{This is a flow diagram that demonstrates how the model works. First developers are required to determine data sensitivity (S), visibility (V), relatedness (R) and granularity (G). With sensitivity, visibility and relatedness calculate the perceived privacy risk. Based on all these parameters make the design decisions on using the data within the system.}
%\end{center}
%\end{figure*} 


The model works as a privacy engineering methodology (PEM) and guides developers to implement privacy in a system as an engineering process. Previous studies have suggested that privacy engineering methods should be simple, explicit and straightforward. It is also suggested that Privacy engineering methods include privacy implementation techniques within the method, so that developers can relate the actions they need to execute once they follow the methodology. We followed these guidelines in implementing this PEM. In constructing this PEM we also followed the work flow for risk management in section 6 of the ISO/IEC 21005:2014 standard \cite {iso2014risk}. The ISO standards for risk management requires a risk management process to have risk identification, risk review and acceptance and finally risk treatment. In this PEM through understanding and evaluating data elements developers conduct risk identification. Then the design decisions based on the understanding address the risk review and acceptance requirements in the ISO standards. The actions executed in order to implement the design decisions handle the risk treatment phase.

With this PEM in place, we conducted the second experiment to qualitatively observe developers engagement with the proposed PEM for understanding data and how understanding data could help them to implement privacy when they design software systems.

\section{Study II}

We designed this experiment based on the same application scenario as in Study I. We recruited participants with industrial software development experience (minimum of 1 year) through university notice boards. Nine participants expressed interest to participate. All participants were in the age range of 25 to 32. Four of the nine participants were female. We first divided the participants into three groups with 2,3 and 4 participants in each group. This was done to see if the number of participants had an effect on the way participants engaged with the model. Participants were asked to decide on a date that suits all members in the group and let us know. With this we allowed the participants to interact before they came for the workshop, so that they would not be complete strangers at the workshop. We conducted three separate workshops with the participants in the lab on the days they agreed on. All workshops were conducted in the same way. Upon arrival the experiment conductor (one of the authors) presented the application scenario. We used a paper template to guide the participants through the proposed PEM. Participants were expected to follow the paper template as a group, replicating how small software teams design systems. Participants were asked to go through the tasks one by one, discussing each step with the members and raising questions if required. The paper template had he following steps to guide the developers through the steps defined in the PEM.


\begin{itemize}
\item Decide the data items developers want to use if you were to design the system.
\item Determine the granularity, sensitivity, visibility and relevance of the data they decided to collect for the system (table 01)
\item Measure the perceived privacy risk for each data item (Using the formula proposed by Senarath and Arachchilage). They were provided with the formula.

\[ \text{Perceived Privacy Risk} = 
\frac{
     \text{Sensitivity} \times \text{Visibility} ^ 3 }
 {  2 \times \text{Relatedness }}
\] [from Senarath and Arachchilage [HICCS paper]]

\item Decide which data they want to store and share in the system.
\item Decide which data they want to share with third parties (advertisers etc.) in the system and how they would share these data (focusing on privacy).
\item Finally, an exit questionnaire to observe how developers perceived the utility of understanding data when implementing privacy into the systems they develop. We asked them 
\begin{itemize}
        \item Did the steps help you to understand the data you used in the system design?
        \item Did understanding data help you to enhance the privacy you implemented in storing and sharing data in the system design?
        \item Do you think organizations would approve using this PEM when they develop software systems?
        \item Would you use and/or encourage using this PEM when designing privacy in software systems?
\end{itemize}
In addition to that we also wanted to evaluate the usefulness and the ease of use of the PEM we proposed for understanding data \cite {venkatesh2000theoretical, legris2003people}. We adopted these two parameters from TAM in order to evaluate the PEM  \cite {venkatesh2000theoretical}. Here we defined usefulness as the usefulness of the PEM in understanding data for implementing privacy in a system design, and ease of use as the general ease in executing the proposed model in order to minimize data in a system design. 
\end{itemize}

Participants were asked to fill out the exit questionnaire individually. One researcher was present in the workshop and made field notes on the observations made. Participants were encouraged to ask questions if needed to clarify the questions. However, since the paper template guided the participants, the interaction of the conductor was purposely kept minimum, to not to bias the participants.

\subsection {data analysis}

We averaged the ratings participants gave for the usefulness and the ease of use of the PEM in the exit questionnaire. However, since we had only 9 participants, we do not go to the extent of forming hypothesis and calculating correlations. Therefore, the analysis was more of a qualitative one. 

We summarized the answers participants gave for the open ended questions in the exit questionnaire. These feedback was used to see how understanding data affected the developers approach in implementing privacy in the system they designed. and what their personal opinions were. The main source we used to observe participants' engagement with the model was the field notes of the experiment conductor. We had 7 pages of field notes recording the observations in the three workshops. We summarized these notes and coded them in NVivo to elicit common findings across the three groups. Total of two coders coded the field notes and the codes were separated under two themes to represent participants' feedback on the two phases in the model, namely the understanding data phase and the system decision making phase. The two coders had 7 and 12 codes respectively. The coders then discussed among themselves and came up with 5 final codes. we discuss these codes in detail in the results section.

\section {Results}

Fig. 03 shows the summary of the results we received for the usefulness and ease of use of the PEM.

%\begin{figure}[h]
%\begin{center}
%\includegraphics[width=0.5\textwidth]{figures/WorkShopTAM}
%\caption{Workshop Participant Feedback on Usefulness and the ease of use of the model}
%\end{center}
%\end{figure}

In average developers rated the usefulness of the model at an average of 7/10 and the ease of using the model as 5.67/10. This suggests that the developers found the PEM useful for understanding data. For example, participants said \enquote{this is very useful}, \enquote{helps to understand important attributes of data}, \enquote{helps to chose and decide data security when designing systems}. When providing guidance for developers it is important that they find it useful. Previous research has revealed that when adopting a new methodology or process in their work environment, software developers main focus is on the usefulness of a methodology \cite {hardgrave2003investigating}. It is further revealed that developers are unlikely to use a method even if it is mandated in an organizational setting, unless they find it useful for them. Therefore, developers feedback saying the system is useful says that developers have a positive attitude towards the proposed PEM.

Table 03 below captures some of the answers participants gave.

\begin{center}
\begin{table*}[htbp]
\caption{Developers' Feedback }
\begin{center}
 \begin{tabular}{|m{10em}|m{36em}|} 
 \hline
\textbf{Participant} & \textbf{ Comment } \\
\hline 
 \multicolumn{2}{|c|}{\textbf{Using the PEM}}\\
\hline
Participant G, group II & \enquote{I see it is quite easy to follow these instructions, and follow the methodology}\\
\hline
Participant E, Group III &  \enquote {Tasks were simple and easy to complete}\\
\hline
Participant D, group II & \enquote {It was easy to use, less time consuming, but needs to be more fine tuned, I prefer doing this individually. Then I could have gotten a better idea}\\
\hline
Participant B, group I & \enquote{I would like to see some tasks, since I have never done something like this before}\\
\hline
\multicolumn{2}{|c|}{\textbf{Usefulness of the PEM}}\\
\hline
Participant A, group I &  \enquote{[The methodology] helps to identify key data}\\
\hline
Participant D, group II & \enquote{The methodology was useful to minimize the data in the system}\\
\hline
Participant A, group I & \enquote {This helps developers to choose what is important and decide what to put in a security policy which helps both the application and managing data}\\
\hline
Participant D, group II & \enquote{This is a quantification criteria, it helps to quantify and minimize data storage}\\
\hline
Participant E, group III & \enquote{An organization would like to boil things down to this level and exercise like this}\\
\hline
Participant F, group II & \enquote {In my opinion, this methodology mostly depends on our inputs and does not do not care much about the costs}\\
\hline
\end{tabular}
\end{center}
\end{table*}
\end{center} 

The PEM had a relatively low score for ease of use. When performing risk calculations participants preferred automated solutions to repetitive tasks. This was primarily due to the paper work involved in following the methodology. We gave the methodology description in a paper and asked the participants to conduct each step manually on paper. Developers in general prefer working on a computer than on pen and paper, and the participants suggested automation of several steps in the process, especially the steps that involved calculations and prioritization of the content based on the calculated scores. Participants requested for calculators while they executed the steps that involved calculations and one participant said \enquote{\textit {it is tedious to do the same calculation over and over again, especially when the numbers are the same}}. 

\begin{itemize}
\item 6/9 participants said that following the PEM helped them to understand data, while the other 2/9 said \textit{it may have helped, but not sure}. One participant said this alone as it is may not be sufficient, however, s/he said that it is very useful. 
\item 3/9 participants said the understanding helped them to implement privacy in the system, 5/9 said that while the understanding helps, the mode still requires to be fine tuned and be improved to include the criteria for embedding privacy for it to be more useful, and one participant said this is not important as the final decision on privacy is usually taken by the organizational management.
\item 4/9 participants said that organizations would like to use this in their system development activities. One participant said \textit{An organization would like to boil things down to this level}. One participant said No, because organizations do not care much about user privacy while 4 others said may be. Another participant said that the use of this PEM would depend on an organization's priorities and resources available for them.
\item 6/9 participants said they would use this method if it is supported in the work environment since it is useful. One participant said s/he would like to use it but s/he doubt if the organization would find something like this important. Two participants said it is better to consider requirements from a functionality perspective rather than a user privacy perspective as it would complicate things in the design phase.
\end{itemize}

Next, we observed how we could interpret the main results we obtained in the survey. 

\subsection{understanding data through categorizing data}

In the survey 91\% of the participants said that they could understand data better through the data categorization process. By analyzing the field notes of the workshop, we identified two codes that explained participants engagement with data categorization. That is \textit{the PEM is useful in understanding data} and \textit{understanding these attributes is important in embedding privacy into a system design}. In the workshop we observed that participants had arguments within the group when they were categorizing data. Developers had to categorize data according to data sensitivity, data visibility and data relevance to the system they were designing. This process encouraged them to engage with the data withing the context of the system. For example, in order to determine how visible the data would be in the system, they had to determine how they would store the data in the system and how they would share the data with other systems. In order to determine the relevance of the data to the system, they had to think of the purpose of the system and define the goals of the system they were designing. Therefore, the process not only made them think of data, but also focus on the system they were designing. 

It was observed that they sometimes changed the visibility of data elements in order to justify their collection decisions. In their feedback some participants suggested that having the same weights 1,2 and 3 for all attributes (sensitivity, visibility and relatedness) may not give the actual risk value for the data elements. They suggested a higher scale to be used for sensitivity. For example, 1 -3 for visibility and relatedness and 1,3,7  for sensitivity categories. One participant said \enquote{\textit {In my opinion, sensitivity should get a higher value as it is more important}}. This is an interesting suggestion we did not anticipate. 

\subsection {collection, storing and sharing of data in the system design}

Three codes explained the observations we made on how participants implemented privacy in the data collection, storage and sharing decisions in the system design following the PEM. \textit{This method makes it easy to justify why we need database protection}, \textit{This helps to understand key data and make sure they are protected} and \textit{This is good, however this needs to be improved}.

Interestingly, we observed that participants did not change their initial decision for data collection after they did the risk calculations. This observation was different to the feedback we got in the survey where 74\% of the participants said that they could further refine their data collection decisions after understanding the data better. Perhaps when developers engage in group work, the environment created a more naturalistic setup in which developers were more concerned about the outcome rather than the process. Therefore, they decided the data to be collected through a thorough discussion at the first stage itself, due to which they did not want to change it along the process. This was the only reason we could hypothesis to explain this difference.

However, participants changed their decisions on data storage and sharing based on the privacy risk they obtained from the model. They stated that this understanding was important and that the methodology encouraged them to look into the data from a user perspective. They also stated that the risk calculation of data and the engagement with data gave them more understanding about the privacy concerns users have and that they could relate their own concerns from a user perspective into the design decisions. 

Following the privacy risk calculation all three groups decided to not store health related data in the system. One group decided to anonymize data and store everything in the cloud encrypted to ensure that data would be secured. One group decided to aggregate data for data sharing and not use individual data from users. Interestingly, participants easily understood the perceived privacy risk for data elements calculated in the model. The perceived privacy risk value in the model is a quantitative parameter. Previous research has shown that developers with IT background find it difficult to grasp qualitative measurements when they try to understand and integrate privacy guidelines into system designs \cite {senarath2018why, oetzel2014systematic}.This was not observed in the participants in our study, perhaps because the guidelines were based on numeric outputs from the model. Participants in one group readily decided that the privacy risk value for a data element should be 4 or less if they have are sharing that data element with third parties. They also suggested that in an industry environment they would prefer the involvement of the organizational management to make these decisions for them.

\section {Discussion}

The proposed PEM is to help software developers to understand data and exercise privacy when they design software systems. This PEM could be applied in situations where a measurement of privacy is required for decisions making. For example, Personal Data Services (PDS) is a recent proposal for enabling user privacy in software systems. PDS defines a personal virtual vault to store user data, which is owned by the user \cite {rubinstein2012big, tene2012big}. The idea is to enable users to control their data and engage with the organizations to decide releasing their data based on benefits they can gain from a particular service. This approach focuses on empowering consumers, transparently communicating what their data could gain \cite {rubinstein2012big}. It is recognized as a potential approach to enable privacy and big data technologies to co-exist while adhering to the requirements of data protection regulations in the GDPR. The approach for understanding data proposed here complements this approach by enabling developers and users to observe the privacy risk of the data they disclose, retrieve when they engage in the decisions to trade data. For example, when releasing data users could rate their data according to sensitivity, and the controller who wants to access the data could give the rating for data visibility and relatedness. The privacy risk of data being available for both the data owner, who releases data and the data controller, who wants to access data and use data would strengthen the transparency in the process. Because without knowing the privacy risk of the data they are disclosing, users do not have all the information about the transaction to make an intelligent decision in disclosing their data.

The workshop results suggest that the PEM works well with the way developers work when they design software systems. That is, developers were happy with the overall time the PEM took and they did not require assistance from the researcher in the workshop room. Therefore, the proposed PEM could be incorporated into the software designing activities within organizational environments. Most privacy guidelines are criticized for being impractical and non realistic when it comes to the actual way developers design and develop software systems. For example, privacy by design is criticized for being theoretical and non practical in guiding developers to embed privacy into the systems they design \cite {spiekermann2012challenges}. Data Minimization is criticized for being un-realistic with modern system design requirements to collect and use user data in large scale \cite {marr2015big}. Previous research has found out that developers find it difficult to adopt privacy guidelines that deviate significantly from the way they usually work and also that developer find it difficult to interpret soft decisions involved with privacy decision making \cite {ayalon2017developers}. For example \textit{avoid using unnecessary data, encrypt sensitive data} without a way for developers to measure which data is necessary and which data is sensitive confuses developers \cite {oetzel2014systematic}. In contrast we observed that developers understood the privacy risk value introduced and they found it easy to work with. Developers suggested that when using this approach their organization should define which is a good risk value for data for the system would be. Therefore, we can assume this PEM would be helpful for developers in their work environments. However, further experiments are needed to evaluate the acceptance of the PEM by developers.

Finally, we also suggest that organizations should focus on educating and training developers to understand data when they design software systems. Our studies suggested that understanding data does help developers to implement privacy when they design systems. Developers demonstrated better privacy in their system designs in the workshop and most importantly they knew why they needed to implement privacy for high risk data. However, current development practices in organizations do not encourage developers to engage with the data they use in systems and the focus is mostly on the system requirements. In most cases, privacy is considered only if it is given in the requirement specification \cite {hadar2017privacy, senarath2018why}. However, if developers could understand the data they use, rather than following a requirement specification and blindly implementing privacy, they could effectively implement privacy in systems to reduce the privacy risks users may encounter in software systems \cite {marr2015big, tene2012big}. 

\section {Conclusion}

This work showed how understanding data and user aspects associated with data could be integrated into the software development processes. The proposed PEM was seen to have a positive impact on developers' efforts to embed privacy into the software system they design. We consider this as an initiative to implement workable practical work-flows to integrate user aspects into developers software development activities. This is important because data privacy is a highly contextual component that is heavily dependent on users, and developers' failure to identify user perceptions on privacy could result in systems that violate user privacy. We believe our research provides an initiative and an example to those who focus on integrating user aspects into the software development process in a way that could be executed with less effort and resources. 




% BALANCE COLUMNS
\balance{}

% REFERENCES FORMAT
% References must be the same font size as other body text.
\bibliographystyle{SIGCHI-Reference-Format}
\bibliography{sample}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
